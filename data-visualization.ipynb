{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data Loading and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import brewer2mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label each emotion with a numerical index \n",
    "emotion = {'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3,\n",
    "           'Sad': 4, 'Surprise': 5, 'Neutral': 6}\n",
    "emo     = ['Angry', 'Fear', 'Happy',\n",
    "           'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "# Unizip the data and set the correct file path \n",
    "import zipfile\n",
    "with zipfile.ZipFile('data/fer2013.zip','r') as zip_ref:\n",
    "    zip_ref.extractall('data')\n",
    "file_path = 'data/fer2013.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that read data from CSV file into arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Re-classifies a  picture with disgust label into angry label\n",
    "# y_train is a pandas df\n",
    "# classes is a list of emotions\n",
    "def emotion_count(y_train, classes):\n",
    "\n",
    "    emo_classcount = {}\n",
    "    print ('Disgust classified as Angry')\n",
    "    \n",
    "    # TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # in the y_train df locate all values that are disgust (1) in the 'emotion' column, replace with anger (0)\n",
    "\n",
    "     # TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # remove disgust from classes \n",
    "\n",
    "\n",
    "    # Mapping emotion labels to numerical value and count each emotion class\n",
    "    for new_num, _class in enumerate(classes):\n",
    "        y_train.loc[(y_train == emotion[_class])] = new_num\n",
    "        class_count = sum(y_train == (new_num))\n",
    "        emo_classcount[_class] = (new_num, class_count)\n",
    "    \n",
    "    return y_train.values, emo_classcount\n",
    "\n",
    "# Load provided CSV dataset and further reshape, rescale the data for feeding\n",
    "def load_data(usage='Training', classes=['Angry','Happy'], filepath='fer2013.csv'):\n",
    "\n",
    "    # TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Read CSV and call it df\n",
    " \n",
    "    df = df[df.Usage == usage]\n",
    "\n",
    "    frames = []\n",
    "    classes.append('Disgust')\n",
    "\n",
    "    # TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Create a dataframe for each class (emotion) and append it to frames\n",
    "  \n",
    "    # TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Concatenate all the dataframes in the list frames to one dataframe \"data\"\n",
    "\n",
    "    # randomize the rows in data \n",
    "    rows = random.sample(list(data.index), int(len(data)))\n",
    "    data = data.loc[rows]\n",
    "\n",
    "    x = list(data[\"pixels\"])\n",
    "    X = []\n",
    "\n",
    "    # Determine the pixels for each image \n",
    "    for i in range(len(x)):\n",
    "        each_pixel = [int(num) for num in x[i].split()]\n",
    "        X.append(each_pixel)\n",
    "\n",
    "    # Reshape into 48*48*1 and rescale\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(X.shape[0], 48, 48,1)\n",
    "    X = X.astype(\"float32\")\n",
    "    X /= 255\n",
    "\n",
    "    # Return image classification data \n",
    "    y_train, new_dict = emotion_count(data.emotion, classes)\n",
    "    y_train = to_categorical(y_train)\n",
    "    return X, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load three sets of data: train, test, validation (find X_train, y_train, X_val, y_val, X_test, y_test using load_data function)\n",
    "X_train, y_train = load_data(classes=emo)\n",
    "\n",
    "X_val, y_val = load_data(usage='PrivateTest', classes=emo, filepath=file_path)\n",
    "\n",
    "X_test, y_test = load_data(usage='PublicTest', classes=emo, filepath=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Print the size of X_train, y_train, X_test, y_test, X_val and y_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data to numpy form and count samples in each label category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store loaded data into numpy form for further processing\n",
    "def save_data(X_test, y_test, fname=''):\n",
    "    np.save( 'X_test' + fname, X_test)\n",
    "    np.save( 'y_test' + fname, y_test)\n",
    "\n",
    "save_data(X_test, y_test,\"_privatetest6_100pct\")\n",
    "X_fname = 'X_test_privatetest6_100pct.npy'\n",
    "y_fname = 'y_test_privatetest6_100pct.npy'\n",
    "\n",
    "# Load images and labels in X and y variables\n",
    "np.load(X_fname)\n",
    "np.load(y_fname)\n",
    "\n",
    "# Convert class probabilities to class indicies and print the count for each class \n",
    "print ('Private test set')\n",
    "y_labels = [np.argmax(lst) for lst in y_train]\n",
    "counts = np.bincount(y_labels)\n",
    "labels = ['angry', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "print (labels)\n",
    "print (counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check variable containing label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View data by plotting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function is used to plot first several pictures for overviewing inputs format\n",
    "# start is the starting image index \n",
    "# end is the ending image index\n",
    "# X is the dataset we want to read from\n",
    "def overview(start, end, X):\n",
    "    # Make a list of labels for each image\n",
    "    Label_y = []\n",
    "    for label in y_labels:\n",
    "      Label_y.append(emo[label])\n",
    "\n",
    "    # TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Set figure with its size 20 x 20\n",
    "\n",
    "    # TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Write a for loop that will loop through the index of each image \n",
    "\n",
    "        # TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # Add each image to the plot \n",
    "\n",
    "        # TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # Label each image with emotion using Label_y list \n",
    "\n",
    "        # TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # Format tight layout\n",
    "\n",
    "    # TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Print the images with labelled emotion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: ------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Call overview on X_train to print the first 200 images \n",
    "image = X_train[0:1, :, :, :]\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one image and print its size and display it from X_train\n",
    "image = X_train[0:1, :, :, :]\n",
    "print(image.shape)\n",
    "plt.imshow(image[0,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training and validation dataset distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up variables for preprocessing\n",
    "y_train = y_train \n",
    "y_public = y_val \n",
    "y_private = y_test \n",
    "y_train_labels  = [np.argmax(lst) for lst in y_train]\n",
    "y_public_labels = [np.argmax(lst) for lst in y_public]\n",
    "y_private_labels = [np.argmax(lst) for lst in y_private]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function is used to plot the distribution of the labels of provided dataset \n",
    "def plot_distribution(y1, y2, data_names, ylims =[1000,1000]): \n",
    "\n",
    "    # Set up the plots\n",
    "    colorset = brewer2mpl.get_map('Set3', 'qualitative', 6).mpl_colors\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.bar(np.arange(1,7), np.bincount(y1), color=colorset, alpha=0.8)\n",
    "    ax1.set_xticks(np.arange(1.25,7.25,1))\n",
    "    ax1.set_xticklabels(labels, rotation=60, fontsize=14)\n",
    "    ax1.set_xlim([0, 8])\n",
    "    ax1.set_ylim([0, ylims[0]])\n",
    "    ax1.set_title(data_names[0])\n",
    "    \n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.bar(np.arange(1,7), np.bincount(y2), color=colorset, alpha=0.8)\n",
    "    ax2.set_xticks(np.arange(1.25,7.24,1))\n",
    "    ax2.set_xticklabels(labels, rotation=60, fontsize=14)\n",
    "    ax2.set_xlim([0, 8])\n",
    "    ax2.set_ylim([0, ylims[1]])\n",
    "    ax2.set_title(data_names[1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Plot the dataset label distributions  \n",
    "plot_distribution(y_train_labels, y_public_labels, \\\n",
    "                  ['Train Dataset', 'Test Dataset'], \\\n",
    "                  ylims=[9000,1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
